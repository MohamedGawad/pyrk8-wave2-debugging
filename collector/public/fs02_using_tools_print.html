<h3 id="getting-comfortable-with-oc">Getting comfortable with oc</h3><p>During this course the student will be required to use the OpenShift Container Platform oc CLI tool.  </p><p>The OpenShift Container Platform (OCP) CLI exposes commands for managing your applications, as well as lower level tools to interact with each component of your system.</p><p>Tasks will describe a challenge.  The student must execute the appropriate command(s) to obtain the needed information.  </p><p>Be sure to review the Step-by-Step instructions and press the green colored button labeled <strong>&quot;Press to mark completed&quot;</strong> once a task has been completed.</p><p>If at any time you are needing assistance press the <strong>Hint</strong> button.  If you are still needing assistance use the <strong>Step-by-Step</strong> button to get detailed instructions for the task.</p><p>Use the <strong>oc</strong> CLI authenticate to the OCP environment.</p><br><pre><code>oc login https://&lt;IP Address&gt;:8443  -u &lt;team&gt; -p &lt;team&gt; --insecure-skip-tls-verify=false<br><br>&lt;IP Address&gt;  - replace with instructor provided information  <br>&lt;team&gt;        - replace with team name</code></pre><br><p>The instructor will provide the IP address needed to access the OCP cluster that will be used in this lab.  </p><br><p>There is no hint necessary for this task.</p><p>Using the OpenShift oc CLI login to the instructor provided environment.</p><br><table class="table-bordered" cellspacing="10"><thead style="background-color: #eee;"><tr style="background-color: #f8f8f8;"><th>Item</th><th>Action</th></tr></thead><tbody><tr style="background-color: #f8f8f8;"><td>&#60;IP Address&#62;</td><td>Replace with instructor provided information</td></tr><tr style="background-color: #f8f8f8;"><td>&#60;team&#62;</td><td>Replace with team name</td></tr></tbody></table><p><strong>oc login https://&#60;IP Address&#62;:8443  -u &#60;team&#62; -p &#60;team&#62; --insecure-skip-tls-verify=false</strong></p><p>Once the command has completed a message will be displayed.  The message will contain a count of projects available to the user.  <em>XXX_</em> will provide the number of projects available to the user. </p><p><strong>Example output:</strong> </p><br><pre><code>Login successful.<br><br>You have access to XXX projects, the list has been suppressed. You can list all projects with &#39;oc projects&#39;<br><br>Using project &lt;team&gt;.</code></pre><blockquote><div><button class="btn btn-success" onclick="markComplete('CS-102 :- MarkComplete 1004 ConfirmButton Login')">Press to mark completed</button></div></blockquote><hr><p>What are the node names in the cluster?  Use the oc to get this information.  Additionally, use the -o wide parameter.  The -o is a small letter O.    </p><p>Get nodes and include the &quot;-o wide&quot; parameter.</p><p>Enter the following command to view the nodes in the cluster. </p><br><pre><code><br>Command:<br><br>    oc get nodes   &lt;and&gt;<br>    oc get nodes -o wide <br><br><br>Example output:<br><br>    From: oc get nodes<br>    NAME                          STATUS    ROLES          AGE       VERSION<br>    sydney.52.117.155.20.nip.io   Ready     compute        3d        v1.11.0+d4cacc0<br>    sydney.52.117.155.26.nip.io   Ready     infra,master   3d        v1.11.0+d4cacc0<br>    sydney.52.117.155.27.nip.io   Ready     compute        3d        v1.11.0+d4cacc0<br>    sydney.52.117.155.29.nip.io   Ready     compute        3d        v1.11.0+d4cacc0<br><br>    From: oc get nodes -o wide<br>    NAME                          STATUS    ROLES          AGE       VERSION           INTERNAL-IP     EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION               CONTAINER-RUNTIME<br>    sydney.52.117.155.20.nip.io   Ready     compute        3d        v1.11.0+d4cacc0   52.117.155.20   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-957.27.2.el7.x86_64   docker://1.13.1<br>    sydney.52.117.155.26.nip.io   Ready     infra,master   3d        v1.11.0+d4cacc0   52.117.155.26   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-957.27.2.el7.x86_64   docker://1.13.1<br>    sydney.52.117.155.27.nip.io   Ready     compute        3d        v1.11.0+d4cacc0   52.117.155.27   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-957.27.2.el7.x86_64   docker://1.13.1<br>    sydney.52.117.155.29.nip.io   Ready     compute        3d        v1.11.0+d4cacc0   52.117.155.29   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-957.27.2.el7.x86_64   docker://1.13.1</code></pre><br><blockquote><br><div><button class="btn btn-success" onclick="markComplete('CS-102 :- MarkComplete 1005 ConfirmButton T01 complete')">Press to mark completed</button></div></blockquote><hr><p>What is the Allocatable cpu count for the master node?  The output from the <strong>describe</strong> is indented to be read by a human being and does not support the -o parameter.</p><p>Describe the master node using the name from previous results.</p><br><pre><code><br>Command:<br><br>    oc describe node &lt;master node name&gt;    <br><br><br>Example output: (View output section Allocatable, and find cpu)<br><br>    Name:               gfstst.169.62.225.197.nip.io<br>    Roles:              infra,master<br>    Labels:             beta.kubernetes.io/arch=amd64<br>                        beta.kubernetes.io/os=linux<br>                        kubernetes.io/hostname=gfstst.169.62.225.197.nip.io<br>                        node-role.kubernetes.io/infra=true<br>                        node-role.kubernetes.io/master=true<br>    Annotations:        node.openshift.io/md5sum=c90cb94827c8f3a55332c5801f709754<br>                        volumes.kubernetes.io/controller-managed-attach-detach=true<br>    CreationTimestamp:  Thu, 29 Aug 2019 08:57:35 -0400<br>    Taints:             &lt;none&gt;<br>    Unschedulable:      false<br>    Conditions:<br>      Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message<br>      ----             ------  -----------------                 ------------------                ------                       -------<br>      OutOfDisk        False   Tue, 10 Sep 2019 21:46:37 -0400   Thu, 29 Aug 2019 08:57:35 -0400   KubeletHasSufficientDisk     kubelet has sufficient disk space available<br>      MemoryPressure   False   Tue, 10 Sep 2019 21:46:37 -0400   Thu, 29 Aug 2019 08:57:35 -0400   KubeletHasSufficientMemory   kubelet has sufficient memory available<br>      DiskPressure     False   Tue, 10 Sep 2019 21:46:37 -0400   Thu, 29 Aug 2019 08:57:35 -0400   KubeletHasNoDiskPressure     kubelet has no disk pressure<br>      PIDPressure      False   Tue, 10 Sep 2019 21:46:37 -0400   Thu, 29 Aug 2019 08:57:35 -0400   KubeletHasSufficientPID      kubelet has sufficient PID available<br>      Ready            True    Tue, 10 Sep 2019 21:46:37 -0400   Thu, 29 Aug 2019 09:01:36 -0400   KubeletReady                 kubelet is posting ready status<br>    Addresses:<br>      InternalIP:  169.62.225.197<br>      Hostname:    gfstst.169.62.225.197.nip.io<br>    Capacity:<br>     cpu:            8<br>     hugepages-1Gi:  0<br>     hugepages-2Mi:  0<br>     memory:         16261076Ki<br>     pods:           250<br>    Allocatable:<br>     cpu:            8              &lt;&lt;&lt;&lt;&lt;&lt;---- Value to be reviewed<br>     hugepages-1Gi:  0<br>     hugepages-2Mi:  0<br>     memory:         16158676Ki<br>     pods:           250<br>    System Info:<br>     Machine ID:                 686738635e44481c83f05005ea080803<br>     System UUID:                5F4CB06B-FD89-3AC3-9BC2-C9F054A57ECA<br>     Boot ID:                    c1d0be9f-6d6e-46dc-9963-2143a81bd814<br>     Kernel Version:             3.10.0-957.27.2.el7.x86_64<br>     OS Image:                   CentOS Linux 7 (Core)<br>     Operating System:           linux<br>     Architecture:               amd64<br>     Container Runtime Version:  docker://1.13.1<br>     Kubelet Version:            v1.11.0+d4cacc0<br>     Kube-Proxy Version:         v1.11.0+d4cacc0<br>    Non-terminated Pods:         (21 in total)<br>      Namespace                  Name                                               CPU Requests  CPU Limits  Memory Requests  Memory Limits<br>      ---------                  ----                                               ------------  ----------  ---------------  -------------<br>      default                    docker-registry-1-hsgwc                            100m (1%)     0 (0%)      256Mi (1%)       0 (0%)<br>      default                    registry-console-1-wc5lk                           0 (0%)        0 (0%)      0 (0%)           0 (0%)<br>      default                    router-1-krxfd                                     100m (1%)     0 (0%)      256Mi (1%)       0 (0%)<br>      kube-system                master-api-gfstst.169.62.225.197.nip.io            0 (0%)        0 (0%)      0 (0%)           0 (0%)<br>      kube-system                master-controllers-gfstst.169.62.225.197.nip.io    0 (0%)        0 (0%)      0 (0%)           0 (0%)<br>      kube-system                master-etcd-gfstst.169.62.225.197.nip.io           0 (0%)        0 (0%)      0 (0%)           0 (0%)<br>      openshift-console          console-54658656b7-h87tz                           100m (1%)     100m (1%)   100Mi (0%)       100Mi (0%)<br>      openshift-monitoring       alertmanager-main-0                                5m (0%)       5m (0%)     210Mi (1%)       10Mi (0%)<br>      openshift-monitoring       alertmanager-main-1                                5m (0%)       5m (0%)     210Mi (1%)       10Mi (0%)<br>      openshift-monitoring       alertmanager-main-2                                5m (0%)       5m (0%)     210Mi (1%)       10Mi (0%)<br>      openshift-monitoring       cluster-monitoring-operator-66cfd97b6d-8qg7c       20m (0%)      20m (0%)    50Mi (0%)        50Mi (0%)<br>      openshift-monitoring       grafana-6b9f85786f-h9fsp                           100m (1%)     200m (2%)   100Mi (0%)       200Mi (1%)<br>      openshift-monitoring       kube-state-metrics-c4f86b5f8-7gpgk                 20m (0%)      40m (0%)    40Mi (0%)        80Mi (0%)<br>      openshift-monitoring       node-exporter-5xwc9                                10m (0%)      20m (0%)    20Mi (0%)        40Mi (0%)<br>      openshift-monitoring       prometheus-k8s-0                                   15m (0%)      15m (0%)    60Mi (0%)        60Mi (0%)<br>      openshift-monitoring       prometheus-k8s-1                                   15m (0%)      15m (0%)    60Mi (0%)        60Mi (0%)<br>      openshift-monitoring       prometheus-operator-6644b8cd54-6cfl9               0 (0%)        0 (0%)      0 (0%)           0 (0%)<br>      openshift-node             sync-gqql7                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)<br>      openshift-sdn              ovs-gtvfc                                          100m (1%)     0 (0%)      300Mi (1%)       0 (0%)<br>      openshift-sdn              sdn-fq2mf                                          100m (1%)     0 (0%)      200Mi (1%)       0 (0%)<br>      openshift-web-console      webconsole-7fc8759f7b-brpgq                        100m (1%)     0 (0%)      100Mi (0%)       0 (0%)<br>    Allocated resources:<br>      (Total limits may be over 100 percent, i.e., overcommitted.)<br>      Resource  Requests      Limits<br>      --------  --------      ------<br>      cpu       795m (9%)     425m (5%)<br>      memory    2172Mi (13%)  620Mi (3%)<br>    Events:     &lt;none&gt;<br></code></pre><br><blockquote><br><div><button class="btn btn-success" onclick="markComplete('CS-102 :- MarkComplete 1006 ConfirmButton T02 complete')">Press to mark completed</button></div></blockquote><hr><p>Display the top CPU and Memory for all nodes.  </p><p>Top is an option of the &quot;oc adm&quot; capability.  Use oc admin --help and review the section labeled &quot;Maintenance&quot;.</p><br><pre><code><br>Command:<br><br>    oc adm top nodes<br><br><br>Example output:<br><br>    NAME                          CPU(cores)   CPU%      MEMORY(bytes)   MEMORY%   <br>    sydney.52.117.155.20.nip.io   156m         1%        2599Mi          33%       <br>    sydney.52.117.155.26.nip.io   607m         7%        6431Mi          40%       <br>    sydney.52.117.155.27.nip.io   362m         4%        3766Mi          48%       <br>    sydney.52.117.155.29.nip.io   145m         1%        2420Mi          31%  <br></code></pre><br><blockquote><br><div><button class="btn btn-success" onclick="markComplete('CS-102 :- MarkComplete 1007 ConfirmButton T03 complete')">Press to mark completed</button></div></blockquote><hr><p>Display the top CPU and Memory for pods in all namespaces.  </p><p>All namespaces can be viewed by using the --all-namespaces parameter for the oc CLI.</p><br><pre><code><br>Command:<br><br>    oc adm top pods --all-namespaces<br><br><br>Example output:<br><br>    NAMESPACE                           NAME                                             CPU(cores)   MEMORY(bytes)   <br>    app-storage                         glusterblock-storage-provisioner-dc-1-bdhb8      0m           11Mi            <br>    app-storage                         glusterfs-storage-2r7rt                          3m           159Mi           <br>    app-storage                         glusterfs-storage-bgj5h                          4m           147Mi           <br>    app-storage                         glusterfs-storage-k5v24                          2m           140Mi           <br>    app-storage                         heketi-storage-1-ph6bl                           0m           16Mi            <br>    default                             dashboard-7cc4b6645c-gpp6d                       0m           21Mi            <br>    default                             docker-registry-1-ccsbq                          1m           17Mi            <br>    default                             registry-console-1-x8t78                         0m           1Mi             <br>    default                             router-1-pfz6m                                   4m           40Mi            <br>    kube-service-catalog                apiserver-gs79m                                  4m           42Mi            <br>    kube-service-catalog                controller-manager-6dtd6                         14m          26Mi            <br>    kube-system                         master-api-sydney.52.117.155.26.nip.io           387m         887Mi           <br>    kube-system                         master-controllers-sydney.52.117.155.26.nip.io   95m          272Mi           <br>    kube-system                         master-etcd-sydney.52.117.155.26.nip.io          33m          529Mi           <br>    nfsprov                             nfs-client-provisioner-9576b7995-cf8x5           2m           10Mi            <br>    openshift-ansible-service-broker    asb-1-h7v4n                                      1m           24Mi            <br>    openshift-console                   console-56c6db78f4-z8f5q                         1m           7Mi             <br>    openshift-infra                     hawkular-cassandra-1-zq6qk                       250m         1336Mi          <br>    openshift-infra                     hawkular-metrics-qxq4q                           34m          668Mi           <br>    openshift-infra                     heapster-vdxq8                                   6m           40Mi            <br>    openshift-metrics-server            metrics-server-56cd9bfcf-tn2bv                   2m           33Mi            <br>    openshift-monitoring                alertmanager-main-0                              2m           27Mi            <br>    openshift-monitoring                alertmanager-main-1                              3m           26Mi            <br>    openshift-monitoring                alertmanager-main-2                              2m           26Mi            <br>    openshift-monitoring                cluster-monitoring-operator-66cfd97b6d-smqh7     0m           32Mi            <br>    openshift-monitoring                grafana-6b9f85786f-l8lk8                         4m           37Mi            <br>    openshift-monitoring                kube-state-metrics-c4f86b5f8-s9j8f               3m           62Mi            <br>    openshift-monitoring                node-exporter-d7h9j                              0m           23Mi            <br>    openshift-monitoring                node-exporter-lgjq9                              1m           24Mi            <br>    openshift-monitoring                node-exporter-nkmbr                              1m           19Mi            <br>    openshift-monitoring                node-exporter-sd55c                              1m           21Mi            <br>    openshift-monitoring                prometheus-k8s-0                                 64m          661Mi           <br>    openshift-monitoring                prometheus-k8s-1                                 61m          616Mi           <br>    openshift-monitoring                prometheus-operator-6644b8cd54-6f75q             0m           22Mi            <br>    openshift-node                      sync-7fq2d                                       0m           2Mi             <br>    openshift-node                      sync-j5fqs                                       0m           21Mi            <br>    openshift-node                      sync-nfvxs                                       0m           2Mi             <br>    openshift-node                      sync-sjnnn                                       0m           2Mi             <br>    openshift-sdn                       ovs-b84v2                                        11m          78Mi            <br>    openshift-sdn                       ovs-dcxc5                                        9m           79Mi            <br>    openshift-sdn                       ovs-xg4jb                                        13m          78Mi            <br>    openshift-sdn                       ovs-zl8tz                                        10m          78Mi            <br>    openshift-sdn                       sdn-22pts                                        7m           43Mi            <br>    openshift-sdn                       sdn-84n5k                                        9m           44Mi            <br>    openshift-sdn                       sdn-9zlkx                                        8m           46Mi            <br>    openshift-sdn                       sdn-nj4q5                                        7m           58Mi            <br>    openshift-template-service-broker   apiserver-bzxlb                                  5m           29Mi            <br>    openshift-web-console               webconsole-7fc8759f7b-dpcjm                      9m           15Mi            <br>    team01                              team01-student-ui-7f47864588-hz7gn               0m           18Mi            <br>    team02                              team02-student-ui-7fdc77b4df-l9k7t               0m           19Mi     <br><br>    . . . additional output removed . . .<br></code></pre><br><blockquote><br><div><button class="btn btn-success" onclick="markComplete('CS-102 :- MarkComplete 1008 ConfirmButton T04 complete')">Press to mark completed</button></div></blockquote><hr><p>What routes exist in all namespaces?</p><p>Be sure to use the --all-namespaces parameter</p><br><pre><code><br>Command:<br><br>    oc get routes --all-namespaces<br><br><br>Example output:<br><br>    NAMESPACE              NAME                HOST/PORT                                                             PATH      SERVICES            PORT      TERMINATION          WILDCARD<br>    app-storage            heketi-storage      heketi-storage-app-storage.gfstst.169.62.225.197.nip.io                         heketi-storage      &lt;all&gt;                          None<br>    default                docker-registry     docker-registry-default.gfstst.169.62.225.197.nip.io                            docker-registry     &lt;all&gt;     passthrough          None<br>    default                registry-console    registry-console-default.gfstst.169.62.225.197.nip.io                           registry-console    &lt;all&gt;     passthrough          None<br>    openshift-console      console             console.gfstst.169.62.225.197.nip.io                                            console             https     reencrypt/Redirect   None<br>    openshift-monitoring   alertmanager-main   alertmanager-main-openshift-monitoring.gfstst.169.62.225.197.nip.io             alertmanager-main   web       reencrypt            None<br>    openshift-monitoring   grafana             grafana-openshift-monitoring.gfstst.169.62.225.197.nip.io                       grafana             https     reencrypt            None<br>    openshift-monitoring   prometheus-k8s      prometheus-k8s-openshift-monitoring.gfstst.169.62.225.197.nip.io                prometheus-k8s      web       reencrypt            None<br></code></pre><br><blockquote><br><div><button class="btn btn-success" onclick="markComplete('CS-102 :- MarkComplete 1009 ConfirmButton T05 complete')">Press to mark completed</button></div></blockquote><hr><p>Get a list of projects, select one and describe the project.  For the selected project what is the default <strong>sa.scc.uid-range</strong> that will be used.</p><p>Use get and describe.</p><br><pre><code><br>Command:<br><br>    oc get projects<br><br>    oc describe project &lt;name of project&gt;<br><br>Example output:<br><br><br>From: oc get projects<br><br>    NAME                                DISPLAY NAME   STATUS<br>    app-storage                                        Active<br>    default                                            Active<br>    kube-public                                        Active<br>    kube-service-catalog                               Active<br>    kube-system                                        Active<br>    management-infra                                   Active<br>    nfsprov                                            Active<br>    openshift                                          Active<br>    openshift-ansible-service-broker                   Active<br>    openshift-console                                  Active<br>    openshift-infra                                    Active<br>    openshift-logging                                  Active<br>    openshift-metrics-server                           Active<br>    openshift-monitoring                               Active<br>    openshift-node                                     Active<br>    openshift-sdn                                      Active<br>    openshift-template-service-broker                  Active<br>    openshift-web-console                              Active<br>    team01                                             Active<br>    team02                                             Active<br><br>    . . . additional output removed . . .<br><br><br>From: oc describe project default         (project name default selected)<br><br>    Name:            default<br>    Created:        3 days ago<br>    Labels:            &lt;none&gt;<br>    Annotations:        openshift.io/node-selector=<br>                openshift.io/sa.scc.mcs=s0:c1,c0<br>                openshift.io/sa.scc.supplemental-groups=1000000000/10000<br>                openshift.io/sa.scc.uid-range=1000000000/10000<br>    Display Name:        &lt;none&gt;<br>    Description:        &lt;none&gt;<br>    Status:            Active<br>    Node Selector:        &lt;none&gt;<br>    Quota:            &lt;none&gt;<br>    Resource limits:    &lt;none&gt;<br><br></code></pre><br><blockquote><br><div><button class="btn btn-success" onclick="markComplete('CS-102 :- MarkComplete 1010 ConfirmButton T06 complete')">Press to mark completed</button></div></blockquote><hr><p>Using the oc adm policy capabilities determine who can get pod information.</p><p>Try <strong>oc adm policy --help</strong> to get more information about how to obtain the information.</p><br><pre><code><br>Command:<br><br>    oc adm policy who-can get pods<br><br><br>Example output:<br><br>    Namespace: default<br>    Verb:      get<br>    Resource:  pods<br><br>    Users:  admin<br>            red<br>            system:admin<br>            system:kube-scheduler<br>            system:serviceaccount:default:router<br>            system:serviceaccount:kube-system:clusterrole-aggregation-controller<br>            system:serviceaccount:kube-system:deployment-controller<br>            system:serviceaccount:kube-system:endpoint-controller<br>            system:serviceaccount:kube-system:generic-garbage-collector<br>            system:serviceaccount:kube-system:namespace-controller<br>            system:serviceaccount:kube-system:persistent-volume-binder<br>            system:serviceaccount:kube-system:pvc-protection-controller<br>            system:serviceaccount:kube-system:statefulset-controller<br>            system:serviceaccount:management-infra:management-admin<br>            system:serviceaccount:nfsprov:deployer<br>            system:serviceaccount:openshift-infra:build-controller<br>            system:serviceaccount:openshift-infra:default-rolebindings-controller<br>            system:serviceaccount:openshift-infra:deployer-controller<br>            system:serviceaccount:openshift-infra:pv-recycler-controller<br>            system:serviceaccount:openshift-infra:sdn-controller<br>            system:serviceaccount:openshift-infra:template-instance-controller<br>            system:serviceaccount:openshift-infra:template-instance-finalizer-controller<br>            system:serviceaccount:openshift-monitoring:cluster-monitoring-operator<br>            system:serviceaccount:openshift-sdn:sdn<br>            team01<br>            team02<br><br>            . . . additional output removed . . .<br><br>    Groups: system:cluster-admins<br>            system:cluster-readers<br>            system:masters<br></code></pre><br><blockquote><br><div><button class="btn btn-success" onclick="markComplete('CS-102 :- MarkComplete 1011 ConfirmButton T07')">Press to mark completed</button></div></blockquote><hr><p>View the oc session configuration.</p><p>Review <strong>oc config --help</strong> for more information.</p><br><pre><code><br>Command:<br><br>    oc config view<br><br><br>Example output:<br><br>    apiVersion: v1<br>    clusters:<br>    - cluster:<br>        certificate-authority-data: REDACTED<br>        server: https://gfstst.169.62.225.197.nip.io:8443<br>      name: gfstst-169-62-225-197-nip-io:8443<br>    contexts:<br>    - context:<br>        cluster: gfstst-169-62-225-197-nip-io:8443<br>        namespace: default<br>        user: system:admin/gfstst-169-62-225-197-nip-io:8443<br>      name: default/gfstst-169-62-225-197-nip-io:8443/system:admin<br>    - context:<br>        cluster: gfstst-169-62-225-197-nip-io:8443<br>        namespace: nfsprov<br>        user: system:admin/gfstst-169-62-225-197-nip-io:8443<br>      name: nfsprov/gfstst-169-62-225-197-nip-io:8443/system:admin<br>    - context:<br>        cluster: gfstst-169-62-225-197-nip-io:8443<br>        namespace: red<br>        user: system:admin/gfstst-169-62-225-197-nip-io:8443<br>      name: red/gfstst-169-62-225-197-nip-io:8443/system:admin<br>    current-context: red/gfstst-169-62-225-197-nip-io:8443/system:admin<br>    kind: Config<br>    preferences: {}<br>    users:<br>    - name: system:admin/gfstst-169-62-225-197-nip-io:8443<br>      user:<br>        client-certificate-data: REDACTED<br>        client-key-data: REDACTED<br></code></pre><br><blockquote><br><div><button class="btn btn-success" onclick="markComplete('CS-102 :- MarkComplete 1012 ConfirmButton T08')">Press to mark completed</button></div></blockquote><hr><p>What are <strong>all</strong> the resources in the default project?  </p><p>Either switch to the default project or use the namespace parameter to get all information.</p><br><pre><code><br>Command:<br>    Option 1:<br><br>    oc project default<br>    oc get all<br><br>    Option 2;<br><br>    oc get all -n default<br><br><br>Example output:<br><br>    NAME                           READY     STATUS    RESTARTS   AGE<br>    pod/dns-limited                1/1       Running   275        11d<br>    pod/docker-registry-1-hsgwc    1/1       Running   0          12d<br>    pod/registry-console-1-wc5lk   1/1       Running   0          12d<br>    pod/router-1-krxfd             1/1       Running   0          12d<br><br>    NAME                                       DESIRED   CURRENT   READY     AGE<br>    replicationcontroller/docker-registry-1    1         1         1         12d<br>    replicationcontroller/registry-console-1   1         1         1         12d<br>    replicationcontroller/router-1             1         1         1         12d<br><br>    NAME                       TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)                   AGE<br>    service/docker-registry    ClusterIP   172.30.87.90   &lt;none&gt;        5000/TCP                  12d<br>    service/kubernetes         ClusterIP   172.30.0.1     &lt;none&gt;        443/TCP,53/UDP,53/TCP     12d<br>    service/registry-console   ClusterIP   172.30.49.26   &lt;none&gt;        9000/TCP                  12d<br>    service/router             ClusterIP   172.30.61.78   &lt;none&gt;        80/TCP,443/TCP,1936/TCP   12d<br><br>    NAME                                                  REVISION   DESIRED   CURRENT   TRIGGERED BY<br>    deploymentconfig.apps.openshift.io/docker-registry    1          1         1         config<br>    deploymentconfig.apps.openshift.io/registry-console   1          1         1         config<br>    deploymentconfig.apps.openshift.io/router             1          1         1         config<br><br>    NAME                                        HOST/PORT                                               PATH      SERVICES           PORT      TERMINATION   WILDCARD<br>    route.route.openshift.io/docker-registry    docker-registry-default.gfstst.169.62.225.197.nip.io              docker-registry    &lt;all&gt;     passthrough   None<br>    route.route.openshift.io/registry-console   registry-console-default.gfstst.169.62.225.197.nip.io             registry-console   &lt;all&gt;     passthrough   None<br><br></code></pre><br><blockquote><br><div><button class="btn btn-success" onclick="markComplete('CS-102 :- MarkComplete 1013 ConfirmButton T09 ')">Press to mark completed</button></div></blockquote><hr><p>View the logs for the pod that starts with “webconsole” in the openshift-web-console namespace.  What IP and port are securely serving the console?</p><p>Get the list of pods in the openshift-web-console namespace to determine the full pod name to view the logs.   </p><p>Review the options for the &quot;Troubleshooting and Debugging Commands&quot; section from <strong>oc --help</strong>.</p><p>Be sure to define the namespace.</p><br><pre><code><br>Command:<br><br>    oc logs webconsole-7fc8759f7b-dpcjm  -n openshift-web-console<br><br><br>Example output:<br><br>    W0913 21:33:08.411930       1 start.go:93] Warning: config.clusterInfo.loggingPublicURL: Invalid value: &quot;&quot;: required to view aggregated container logs in the console, web console start will continue.<br>    I0913 21:33:08.998336       1 start.go:208] OpenShift Web Console Version: v3.11.0+ea42280<br>    I0913 21:33:08.998683       1 serve.go:89] Serving securely on 0.0.0.0:8443.  &lt;&lt;&lt;--- view this line<br><br></code></pre><br><blockquote><br><div><button class="btn btn-success" onclick="markComplete('CS-102 :- MarkComplete 1014 ConfirmButton T10')">Press to mark completed</button></div></blockquote><hr><p>Switch to the project for your team.  RSH into the pod that starts with <strong>&#60;team&#62;-student-ui-</strong>   </p><p>Replace <strong>&#60;team&#62;</strong> with your team name.</p><p>Change to the project.</p><p>Start a shell session in a pod the pod.</p><p>View the oc --help section labeled &quot;Troubleshooting and Debugging Commands&quot;</p><br><pre><code><br>Command:<br><br>    oc project team01<br><br>Example output: <br><br>    Now using project &quot;team01&quot; on server &quot;https://52.117.155.26:8443&quot;.<br><br><br><br>Command:    <br><br>    oc get po<br><br>Example output: <br><br>    NAME                                 READY     STATUS    RESTARTS   AGE<br>    team01-student-ui-7f47864588-hz7gn   1/1       Running   0          1d<br><br><br><br>Command: <br><br>    oc rsh team01-student-ui-7f47864588-hz7gn    <br>Example output:<br><br>    /collector        <br></code></pre><br><blockquote><br><div><button class="btn btn-success" onclick="markComplete('CS-102 :- MarkComplete 1015 ConfirmButton T11')">Press to mark completed</button></div></blockquote><hr><p>Without using an interactive shell prompt, list the files in directory /collector/lib in the pod that starts with <strong>&#60;team&#62;-student-ui-</strong>   </p><p>Replace <strong>&#60;team&#62;</strong> with your team name.</p><p>The command syntax needs the <strong>-it</strong> and <strong>--</strong> followed by the command to list the files. </p><p>ls -la /collector/lib will list the files.</p><br><pre><code><br>Command:<br><br>    oc exec team01-student-ui-7f47864588-hz7gn  -it -- ls -la /collector/lib<br><br>    (if not in the &lt;team&gt; project add the -n &lt;team&gt; parameter)<br><br><br>Example output:<br><br>    total 132<br>    drwxrwxrwx    1 appuser  appusers      4096 Sep 13 23:44 .<br>    drwxrwxrwx    1 root     root          4096 Sep 13 23:44 ..<br>    -rwxrwxrwx    1 appuser  appusers     20786 Aug 14 20:38 cllr.js<br>    -rwxrwxrwx    1 appuser  appusers      4671 Aug 14 20:38 config.js<br>    -rwxrwxrwx    1 appuser  appusers      8030 Aug 15 15:25 courses.js<br>    -rwxrwxrwx    1 appuser  appusers     10738 Aug 14 20:38 insight.js<br>    -rwxrwxrwx    1 appuser  appusers     23135 Sep 12 01:38 parseHtmlBuffer.js<br>    -rwxrwxrwx    1 appuser  appusers      4405 Aug 14 20:38 printCourse.js<br>    -rwxrwxrwx    1 appuser  appusers      5499 Aug 17 14:59 student.js<br>    -rwxrwxrwx    1 appuser  appusers      2879 Aug 14 20:38 utl.js<br>    -rwxrwxrwx    1 appuser  appusers     28027 Aug 14 20:38 validateBuffer.js</code></pre><br><blockquote><br><div><button class="btn btn-success" onclick="markComplete('CS-102 :- MarkComplete 1016 ConfirmButton T12 ')">Press to mark completed</button></div></blockquote><hr><p>Within your team project run a pod named <strong>&#60;team&#62;-busybox</strong> using the &quot;busybox&quot; image, open an interactive session, and never restart the pod. </p><p>A single command can be used to accomplish all of the above.</p><p>Replace <strong>&#60;team&#62;</strong> with your team name.</p><p>Once the interactive prompt opens run the following command:</p><p>cat /etc/resolv.conf</p><p>Exit the interactive session.</p><p>Ensure to use the -it, --image, and --restart options</p><br><pre><code><br>Command:<br><br>    oc run -it team01-busybox --image=busybox --restart=Never<br><br>Example output:<br><br>    If you don&#39;t see a command prompt, try pressing enter.<br>    / #<br><br><br><br>Command in the interactive session:<br><br>    cat /etc/resolv.conf<br><br>Example output:<br><br>    nameserver 10.171.184.210<br>    search team01.svc.cluster.local svc.cluster.local cluster.local<br>    options ndots:5<br><br><br>Command in the interactive session:<br><br>    exit<br><br>Example output:<br><br>    The command prompt from the terminal session will be shown.<br></code></pre><br><blockquote><br><div><button class="btn btn-success" onclick="markComplete('CS-102 :- MarkComplete 1017 ConfirmButton T13')">Press to mark completed</button></div></blockquote><hr><p>Using the pod created in the previous task edit the pod (named <strong>&#60;team&#62;-busybox</strong>) adding the following label in the metadata.labels section.</p><p>  work: training</p><p>Save the changes and then describe the pod to validate the label is defined.</p><p>When the pod is saved and you attempt to close the editor it will not close if the proper syntax is not used.</p><p>Now, add a second annotation by usin the oc patch and not edit.  Patch uses the -p parameter followed by the patch data.  The input for the patch would be JSON formatted.  This additional annotation should be:</p><br><pre><code>play: gaming</code></pre><p>Example:</p><p> &#39;{&quot;metadata&quot;:{&quot;annotations&quot;:{&quot;play&quot;:&quot;gaming&quot;}}}&#39;</p><p>The default editor &quot;vi&quot; will open when the command is executed.  If you desire to use the “nano” editor add the following parameter:</p><p><strong>KUBE_EDITOR=&quot;nano&quot;</strong> oc edit po &#60;team&#62;-busybox</p><br><pre><code><br>Command:<br><br>    oc edit po team01-busybox<br><br>Example output:<br><br><br>    # Please edit the object below. Lines beginning with a &#39;#&#39; will be ignored,<br>    # and an empty file will abort the edit. If an error occurs while saving this file will be<br>    # reopened with the relevant failures.<br>    #<br>    apiVersion: v1<br>    kind: Pod<br>    metadata:<br>      annotations:<br>        openshift.io/scc: anyuid<br>      creationTimestamp: 2019-09-17T21:57:03Z<br>      labels:<br>        run: team01-busybox         &lt;&lt;&lt;--- insert new all after this line<br>      name: team01-busybox<br>      namespace: team01<br>      resourceVersion: &quot;962458&quot;<br>      selfLink: /api/v1/namespaces/team01/pods/team01-busybox<br>      uid: 151c3f3f-d996-11e9-ab08-06c0ef66d8ff<br>    spec:<br><br>    . . . additional output removed . . .<br><br><br><br>Insert the following in the editor<br><br>    work: training<br><br>Save the modified pod definition file:<br><br><br><br>Command:<br><br>    oc describe po team01-busybox<br><br>Example output:<br><br>    Name:               team01-busybox<br>    Namespace:          team01<br>    Priority:           0<br>    PriorityClassName:  &lt;none&gt;<br>    Node:               sydney.52.117.155.29.nip.io/52.117.155.29<br>    Start Time:         Tue, 17 Sep 2019 16:57:03 -0500<br>    Labels:             run=team01-busybox<br>                        work=training<br>    Annotations:        openshift.io/scc=anyuid<br>    Status:             Succeeded<br><br>    . . . additional output removed . . .<br><br><br>Command:<br><br>    oc patch po team01-student-ui-7f47864588-hz7gn -p &#39;{&quot;metadata&quot;:{&quot;annotations&quot;:{&quot;play&quot;:&quot;gaming&quot;}}}&#39;<br><br><br>Example output:<br><br>    pod/team01-student-ui-7f47864588-hz7gn patched<br><br><br>Command:<br><br>    oc describe po team01-busybox<br><br>Example output:<br><br>    Name:               team01-busybox<br>    Namespace:          team01<br>    Priority:           0<br>    PriorityClassName:  &lt;none&gt;<br>    Node:               sydney.52.117.155.29.nip.io/52.117.155.29<br>    Start Time:         Tue, 17 Sep 2019 16:57:03 -0500<br>    Labels:             run=team01-busybox<br>                        work=training<br>                        play=gaming<br>    Annotations:        openshift.io/scc=anyuid<br>    Status:             Succeeded<br><br>    . . . additional output removed . . .    </code></pre><br><blockquote><br><div><button class="btn btn-success" onclick="markComplete('CS-102 :- MarkComplete 1018 ConfirmButton T14')">Press to mark completed</button></div></blockquote><hr><p>Delete the pod created a previous task named <strong>&#60;team&#62;-busybox</strong>.</p><p>Ensure a pod is deleted.</p><p>Ensure to include the proper namespace or switch to the project where the pod was created.</p><br><pre><code><br>Command:<br><br>    oc delete po team01-busybox<br><br>Example output:<br><br>    pod &quot;team01-busybox&quot; deleted<br></code></pre><br><blockquote><br><div><button class="btn btn-success" onclick="markComplete('CS-102 :- MarkComplete 1019 ConfirmButton T15')">Press to mark completed</button></div></blockquote><hr><p>Get storage related resources Persistent Volumes and Storage Classes for the cluster and get Persistent Volumes Claims for all namespaces.</p><p>Abbreivations can be used:</p><br><table class="table-bordered" cellspacing="10"><thead style="background-color: #eee;"><tr style="background-color: #f8f8f8;"><th align="center">Abbr</th><th align="left">Resource</th><th align="center">Namespaced</th></tr></thead><tbody><tr style="background-color: #f8f8f8;"><td align="center">pv</td><td align="left">Persistent Volumes</td><td align="center">no</td></tr><tr style="background-color: #f8f8f8;"><td align="center">sc</td><td align="left">StorageClass</td><td align="center">no</td></tr><tr style="background-color: #f8f8f8;"><td align="center">pvc</td><td align="left">Persistent Volumes Claims</td><td align="center">yes</td></tr></tbody></table><br><pre><code><br>Command:<br><br>    oc get pv<br><br>Example output:<br><br>    NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS    CLAIM                STORAGECLASS          REASON    AGE<br>    pvc-b209ee09-d66e-11e9-ab08-06c0ef66d8ff   1Mi        RWX            Delete           Bound     nfsprov/test-claim   managed-nfs-storage             4d<br><br><br><br>Command:<br><br>    oc get sc<br><br>Example output:<br><br>    NAME                      PROVISIONER                AGE<br>    glusterfs-storage         kubernetes.io/glusterfs    4d<br>    glusterfs-storage-block   gluster.org/glusterblock   4d<br>    managed-nfs-storage       myokd/nfs                  4d<br><br><br><br>Command:<br><br>    oc get pvc --all-namespaces<br><br>Example output:<br><br>    NAMESPACE   NAME         STATUS    VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS          AGE<br>    nfsprov     test-claim   Bound     pvc-b209ee09-d66e-11e9-ab08-06c0ef66d8ff   1Mi        RWX            managed-nfs-storage   4d        <br></code></pre><br><blockquote><br><div><button class="btn btn-success" onclick="markComplete('CS-102 :- MarkComplete 1020 ConfirmButton T16')">Press to mark completed</button></div></blockquote><hr><p>List all supported API resources on the server in the cluster.  Ensure the <strong>-o wide</strong> parameter is included to provide the VERBS permitted for each resource.</p><p>View the section labeled &quot;Advanced Commands&quot; output from oc --help command.</p><br><pre><code><br>Command:<br><br>    oc api-resources<br><br><br>Example output:<br><br>    NAME                                  SHORTNAMES     APIGROUP                       NAMESPACED   KIND                                 VERBS<br>    bindings                                                                            true         Binding                              [create]<br>    componentstatuses                     cs                                            false        ComponentStatus                      [get list]<br>    configmaps                            cm                                            true         ConfigMap                            [create delete deletecollection get list patch update watch]<br>    endpoints                             ep                                            true         Endpoints                            [create delete deletecollection get list patch update watch]<br>    events                                ev                                            true         Event                                [create delete deletecollection get list patch update watch]<br>    limitranges                           limits                                        true         LimitRange                           [create delete deletecollection get list patch update watch]<br>    namespaces                            ns                                            false        Namespace                            [create delete get list patch update watch]<br>    nodes                                 no                                            false        Node                                 [create delete deletecollection get list patch update watch]<br>    persistentvolumeclaims                pvc                                           true         PersistentVolumeClaim                [create delete deletecollection get list patch update watch]<br>    persistentvolumes                     pv                                            false        PersistentVolume                     [create delete deletecollection get list patch update watch]<br>    pods                                  po                                            true         Pod                                  [create delete deletecollection get list patch update watch]<br>    podtemplates                                                                        true         PodTemplate                          [create delete deletecollection get list patch update watch]<br>    replicationcontrollers                rc                                            true         ReplicationController                [create delete deletecollection get list patch update watch]<br>    resourcequotas                        quota                                         true         ResourceQuota                        [create delete deletecollection get list patch update watch]<br>    secrets                                                                             true         Secret                               [create delete deletecollection get list patch update watch]<br>    securitycontextconstraints            scc                                           false        SecurityContextConstraints           [create delete deletecollection get list patch update watch]<br>    serviceaccounts                       sa                                            true         ServiceAccount                       [create delete deletecollection get list patch update watch]<br>    services                              svc                                           true         Service                              [create delete get list patch update watch]<br>    mutatingwebhookconfigurations                        admissionregistration.k8s.io   false        MutatingWebhookConfiguration         [create delete deletecollection get list patch update watch]<br>    validatingwebhookconfigurations                      admissionregistration.k8s.io   false        ValidatingWebhookConfiguration       [create delete deletecollection get list patch update watch]<br>    customresourcedefinitions             crd,crds       apiextensions.k8s.io           false        CustomResourceDefinition             [create delete deletecollection get list patch update watch]<br>    apiservices                                          apiregistration.k8s.io         false        APIService                           [create delete deletecollection get list patch update watch]<br>    controllerrevisions                                  apps                           true         ControllerRevision                   [create delete deletecollection get list patch update watch]<br>    daemonsets                            ds             apps                           true         DaemonSet                            [create delete deletecollection get list patch update watch]<br>    deployments                           deploy         apps                           true         Deployment                           [create delete deletecollection get list patch update watch]<br>    replicasets                           rs             apps                           true         ReplicaSet                           [create delete deletecollection get list patch update watch]<br>    statefulsets                          sts            apps                           true         StatefulSet                          [create delete deletecollection get list patch update watch]<br>    deploymentconfigs                     dc             apps.openshift.io              true         DeploymentConfig                     [create delete deletecollection get list patch update watch]<br>    tokenreviews                                         authentication.k8s.io          false        TokenReview                          [create]<br>    localsubjectaccessreviews                            authorization.k8s.io           true         LocalSubjectAccessReview             [create]<br>    selfsubjectaccessreviews                             authorization.k8s.io           false        SelfSubjectAccessReview              [create]<br>    selfsubjectrulesreviews                              authorization.k8s.io           false        SelfSubjectRulesReview               [create]<br>    subjectaccessreviews                                 authorization.k8s.io           false        SubjectAccessReview                  [create]<br>    clusterrolebindings                                  authorization.openshift.io     false        ClusterRoleBinding                   [create delete get list patch update]<br>    clusterroles                                         authorization.openshift.io     false        ClusterRole                          [create delete get list patch update]<br>    localresourceaccessreviews                           authorization.openshift.io     true         LocalResourceAccessReview            [create]<br>    localsubjectaccessreviews                            authorization.openshift.io     true         LocalSubjectAccessReview             [create]<br>    resourceaccessreviews                                authorization.openshift.io     false        ResourceAccessReview                 [create]<br>    rolebindingrestrictions                              authorization.openshift.io     true         RoleBindingRestriction               [create delete deletecollection get list patch update watch]<br>    rolebindings                                         authorization.openshift.io     true         RoleBinding                          [create delete get list patch update]<br>    roles                                                authorization.openshift.io     true         Role                                 [create delete get list patch update]<br>    selfsubjectrulesreviews                              authorization.openshift.io     true         SelfSubjectRulesReview               [create]<br>    subjectaccessreviews                                 authorization.openshift.io     false        SubjectAccessReview                  [create]<br>    subjectrulesreviews                                  authorization.openshift.io     true         SubjectRulesReview                   [create]<br>    bundlebindings                                       automationbroker.io            true         BundleBinding                        [delete deletecollection get list patch create update watch]<br>    bundleinstances                                      automationbroker.io            true         BundleInstance                       [delete deletecollection get list patch create update watch]<br>    bundles                                              automationbroker.io            true         Bundle                               [delete deletecollection get list patch create update watch]<br>    horizontalpodautoscalers              hpa            autoscaling                    true         HorizontalPodAutoscaler              [create delete deletecollection get list patch update watch]<br>    cronjobs                              cj             batch                          true         CronJob                              [create delete deletecollection get list patch update watch]<br>    jobs                                                 batch                          true         Job                                  [create delete deletecollection get list patch update watch]<br>    buildconfigs                          bc             build.openshift.io             true         BuildConfig                          [create delete deletecollection get list patch update watch]<br>    builds                                               build.openshift.io             true         Build                                [create delete deletecollection get list patch update watch]<br>    certificatesigningrequests            csr            certificates.k8s.io            false        CertificateSigningRequest            [create delete deletecollection get list patch update watch]<br>    events                                ev             events.k8s.io                  true         Event                                [create delete deletecollection get list patch update watch]<br>    daemonsets                            ds             extensions                     true         DaemonSet                            [create delete deletecollection get list patch update watch]<br>    deployments                           deploy         extensions                     true         Deployment                           [create delete deletecollection get list patch update watch]<br>    ingresses                             ing            extensions                     true         Ingress                              [create delete deletecollection get list patch update watch]<br>    networkpolicies                       netpol         extensions                     true         NetworkPolicy                        [create delete deletecollection get list patch update watch]<br>    podsecuritypolicies                   psp            extensions                     false        PodSecurityPolicy                    [create delete deletecollection get list patch update watch]<br>    replicasets                           rs             extensions                     true         ReplicaSet                           [create delete deletecollection get list patch update watch]<br>    images                                               image.openshift.io             false        Image                                [create delete deletecollection get list patch update watch]<br>    imagesignatures                                      image.openshift.io             false        ImageSignature                       [create delete]<br>    imagestreamimages                     isimage        image.openshift.io             true         ImageStreamImage                     [get]<br>    imagestreamimports                                   image.openshift.io             true         ImageStreamImport                    [create]<br>    imagestreammappings                                  image.openshift.io             true         ImageStreamMapping                   [create]<br>    imagestreams                          is             image.openshift.io             true         ImageStream                          [create delete deletecollection get list patch update watch]<br>    imagestreamtags                       istag          image.openshift.io             true         ImageStreamTag                       [create delete get list patch update]<br>    nodes                                                metrics.k8s.io                 false        NodeMetrics                          [get list]<br>    pods                                                 metrics.k8s.io                 true         PodMetrics                           [get list]<br>    alertmanagers                                        monitoring.coreos.com          true         Alertmanager                         [delete deletecollection get list patch create update watch]<br>    prometheuses                                         monitoring.coreos.com          true         Prometheus                           [delete deletecollection get list patch create update watch]<br>    prometheusrules                                      monitoring.coreos.com          true         PrometheusRule                       [delete deletecollection get list patch create update watch]<br>    servicemonitors                                      monitoring.coreos.com          true         ServiceMonitor                       [delete deletecollection get list patch create update watch]<br>    clusternetworks                                      network.openshift.io           false        ClusterNetwork                       [create delete deletecollection get list patch update watch]<br>    egressnetworkpolicies                                network.openshift.io           true         EgressNetworkPolicy                  [create delete deletecollection get list patch update watch]<br>    hostsubnets                                          network.openshift.io           false        HostSubnet                           [create delete deletecollection get list patch update watch]<br>    netnamespaces                                        network.openshift.io           false        NetNamespace                         [create delete deletecollection get list patch update watch]<br>    networkpolicies                       netpol         networking.k8s.io              true         NetworkPolicy                        [create delete deletecollection get list patch update watch]<br>    oauthaccesstokens                                    oauth.openshift.io             false        OAuthAccessToken                     [create delete deletecollection get list patch update watch]<br>    oauthauthorizetokens                                 oauth.openshift.io             false        OAuthAuthorizeToken                  [create delete deletecollection get list patch update watch]<br>    oauthclientauthorizations                            oauth.openshift.io             false        OAuthClientAuthorization             [create delete deletecollection get list patch update watch]<br>    oauthclients                                         oauth.openshift.io             false        OAuthClient                          [create delete deletecollection get list patch update watch]<br>    poddisruptionbudgets                  pdb            policy                         true         PodDisruptionBudget                  [create delete deletecollection get list patch update watch]<br>    podsecuritypolicies                   psp            policy                         false        PodSecurityPolicy                    [create delete deletecollection get list patch update watch]<br>    projectrequests                                      project.openshift.io           false        ProjectRequest                       [create list]<br>    projects                                             project.openshift.io           false        Project                              [create delete get list patch update watch]<br>    appliedclusterresourcequotas                         quota.openshift.io             true         AppliedClusterResourceQuota          [get list]<br>    clusterresourcequotas                 clusterquota   quota.openshift.io             false        ClusterResourceQuota                 [create delete deletecollection get list patch update watch]<br>    clusterrolebindings                                  rbac.authorization.k8s.io      false        ClusterRoleBinding                   [create delete deletecollection get list patch update watch]<br>    clusterroles                                         rbac.authorization.k8s.io      false        ClusterRole                          [create delete deletecollection get list patch update watch]<br>    rolebindings                                         rbac.authorization.k8s.io      true         RoleBinding                          [create delete deletecollection get list patch update watch]<br>    roles                                                rbac.authorization.k8s.io      true         Role                                 [create delete deletecollection get list patch update watch]<br>    routes                                               route.openshift.io             true         Route                                [create delete deletecollection get list patch update watch]<br>    priorityclasses                       pc             scheduling.k8s.io              false        PriorityClass                        [create delete deletecollection get list patch update watch]<br>    podsecuritypolicyreviews                             security.openshift.io          true         PodSecurityPolicyReview              [create]<br>    podsecuritypolicyselfsubjectreviews                  security.openshift.io          true         PodSecurityPolicySelfSubjectReview   [create]<br>    podsecuritypolicysubjectreviews                      security.openshift.io          true         PodSecurityPolicySubjectReview       [create]<br>    rangeallocations                                     security.openshift.io          false        RangeAllocation                      [create delete deletecollection get list patch update watch]<br>    securitycontextconstraints            scc            security.openshift.io          false        SecurityContextConstraints           [create delete deletecollection get list patch update watch]<br>    clusterservicebrokers                                servicecatalog.k8s.io          false        ClusterServiceBroker                 [create delete deletecollection get list patch update watch]<br>    clusterserviceclasses                                servicecatalog.k8s.io          false        ClusterServiceClass                  [create delete deletecollection get list patch update watch]<br>    clusterserviceplans                                  servicecatalog.k8s.io          false        ClusterServicePlan                   [create delete deletecollection get list patch update watch]<br>    servicebindings                                      servicecatalog.k8s.io          true         ServiceBinding                       [create delete deletecollection get list patch update watch]<br>    servicebrokers                                       servicecatalog.k8s.io          true         ServiceBroker                        [create delete deletecollection get list patch update watch]<br>    serviceclasses                                       servicecatalog.k8s.io          true         ServiceClass                         [create delete deletecollection get list patch update watch]<br>    serviceinstances                                     servicecatalog.k8s.io          true         ServiceInstance                      [create delete deletecollection get list patch update watch]<br>    serviceplans                                         servicecatalog.k8s.io          true         ServicePlan                          [create delete deletecollection get list patch update watch]<br>    storageclasses                        sc             storage.k8s.io                 false        StorageClass                         [create delete deletecollection get list patch update watch]<br>    volumeattachments                                    storage.k8s.io                 false        VolumeAttachment                     [create delete deletecollection get list patch update watch]<br>    brokertemplateinstances                              template.openshift.io          false        BrokerTemplateInstance               [create delete deletecollection get list patch update watch]<br>    processedtemplates                                   template.openshift.io          true         Template                             [create]<br>    templateinstances                                    template.openshift.io          true         TemplateInstance                     [create delete deletecollection get list patch update watch]<br>    templates                                            template.openshift.io          true         Template                             [create delete deletecollection get list patch update watch]<br>    groups                                               user.openshift.io              false        Group                                [create delete deletecollection get list patch update watch]<br>    identities                                           user.openshift.io              false        Identity                             [create delete deletecollection get list patch update watch]<br>    useridentitymappings                                 user.openshift.io              false        UserIdentityMapping                  [create delete get patch update]<br>    users                                                user.openshift.io              false        User                                 [create delete deletecollection get list patch update watch]    </code></pre><br><blockquote><br><div><button class="btn btn-success" onclick="markComplete('CS-102 :- MarkComplete 1021 ConfirmButton T17')">Press to mark completed</button></div></blockquote><hr><p>Using the -v 9 parameter get the pods in your team namespace. The -v parameter will display detail communication sent to the cluster API server.</p><p>Did your output include any <strong>curl</strong> commands?</p><p>Ensure you are in the team project or include the -n <team> parameter.</p><br><pre><code><br>Command:<br><br>    oc get po -n team01 -v 9<br><br>Example output:<br><br>    I0917 19:28:48.023894   66924 loader.go:359] Config loaded from file /Users/daveweilert/.kube/config<br>    I0917 19:28:48.027878   66924 loader.go:359] Config loaded from file /Users/daveweilert/.kube/config<br>    I0917 19:28:48.034776   66924 loader.go:359] Config loaded from file /Users/daveweilert/.kube/config<br>    I0917 19:28:48.041968   66924 loader.go:359] Config loaded from file /Users/daveweilert/.kube/config<br>    I0917 19:28:48.042310   66924 round_trippers.go:386] curl -k -v -XGET  -H &quot;Accept: application/json;as=Table;v=v1beta1;g=meta.k8s.io, application/json&quot; -H &quot;User-Agent: oc/v1.11.0+d4cacc0 (darwin/amd64) kubernetes/d4cacc0&quot; -H &quot;Authorization: Bearer fKqnT6ZLdI0PLYbyXGzjwUxWHr6H87cCwJUBwvq9Ktk&quot; &#39;https://52.117.155.26:8443/api/v1/namespaces/team01/pods?limit=500&#39;<br>    I0917 19:28:48.104043   66924 round_trippers.go:405] GET https://52.117.155.26:8443/api/v1/namespaces/team01/pods?limit=500 200 OK in 61 milliseconds<br>    I0917 19:28:48.104098   66924 round_trippers.go:411] Response Headers:<br>    I0917 19:28:48.104113   66924 round_trippers.go:414]     Date: Wed, 18 Sep 2019 00:28:48 GMT<br>    I0917 19:28:48.104122   66924 round_trippers.go:414]     Cache-Control: no-store<br>    I0917 19:28:48.104140   66924 round_trippers.go:414]     Content-Type: application/json<br>    I0917 19:28:48.104151   66924 round_trippers.go:414]     Content-Length: 3385<br>    I0917 19:28:48.104238   66924 request.go:897] Response Body: {&quot;kind&quot;:&quot;Table&quot;,&quot;apiVersion&quot;:&quot;meta.k8s.io/v1beta1&quot;,&quot;metadata&quot;:{&quot;selfLink&quot;:&quot;/api/v1/namespaces/team01/pods&quot;,&quot;resourceVersion&quot;:&quot;986995&quot;},&quot;columnDefinitions&quot;:[{&quot;name&quot;:&quot;Name&quot;,&quot;type&quot;:&quot;string&quot;,&quot;format&quot;:&quot;name&quot;,&quot;description&quot;:&quot;Name must be unique within a namespace. Is required when creating resources, although some resources may allow a client to request the generation of an appropriate name automatically. Name is primarily intended for creation idempotence and configuration definition. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names&quot;,&quot;priority&quot;:0},{&quot;name&quot;:&quot;Ready&quot;,&quot;type&quot;:&quot;string&quot;,&quot;format&quot;:&quot;&quot;,&quot;description&quot;:&quot;The aggregate readiness state of this pod for accepting traffic.&quot;,&quot;priority&quot;:0},{&quot;name&quot;:&quot;Status&quot;,&quot;type&quot;:&quot;string&quot;,&quot;format&quot;:&quot;&quot;,&quot;description&quot;:&quot;The aggregate status of the containers in this pod.&quot;,&quot;priority&quot;:0},{&quot;name&quot;:&quot;Restarts&quot;,&quot;type&quot;:&quot;integer&quot;,&quot;format&quot;:&quot;&quot;,&quot;description&quot;:&quot;The number of times the containers in this pod have been restarted.&quot;,&quot;priority&quot;:0},{&quot;name&quot;:&quot;Age&quot;,&quot;type&quot;:&quot;string&quot;,&quot;format&quot;:&quot;&quot;,&quot;description&quot;:&quot;CreationTimestamp is a timestamp representing the server time when this object was created. It is not guaranteed to be set in happens-before order across separate operations. Clients may not set this value. It is represented in RFC3339 form and is in UTC.\n\nPopulated by the system. Read-only. Null for lists. More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#metadata&quot;,&quot;priority&quot;:0},{&quot;name&quot;:&quot;IP&quot;,&quot;type&quot;:&quot;string&quot;,&quot;format&quot;:&quot;&quot;,&quot;description&quot;:&quot;IP address allocated to the pod. Routable at least within the cluster. Empty if not yet allocated.&quot;,&quot;priority&quot;:1},{&quot;name&quot;:&quot;Node&quot;,&quot;type&quot;:&quot;string&quot;,&quot;format&quot;:&quot;&quot;,&quot;description&quot;:&quot;NodeName is a request to schedule this pod onto a specific node. If it is non-empty, the scheduler simply schedules this pod onto that node, assuming that it fits resource requirements.&quot;,&quot;priority&quot;:1},{&quot;name&quot;:&quot;Nominated Node&quot;,&quot;type&quot;:&quot;string&quot;,&quot;format&quot;:&quot;&quot;,&quot;description&quot;:&quot;nominatedNodeName is set only when this pod preempts other pods on the node, but it cannot be scheduled right away as preemption victims receive their graceful termination periods. This field does not guarantee that the pod will be scheduled on this node. Scheduler may decide to place the pod elsewhere if other nodes become available sooner. Scheduler may also decide to give the resources on this node to a higher priority pod that is created after preemption. As a result, this field may be different than PodSpec.nodeName when the pod is scheduled.&quot;,&quot;priority&quot;:1}],&quot;rows&quot;:[{&quot;cells&quot;:[&quot;team01-student-ui-7f47864588-hz7gn&quot;,&quot;1/1&quot;,&quot;Running&quot;,0,&quot;1d&quot;,&quot;10.130.0.223&quot;,&quot;sydney.52.117.155.27.nip.io&quot;,&quot;\u003cnone\u003e&quot;],&quot;object&quot;:{&quot;kind&quot;:&quot;PartialObjectMetadata&quot;,&quot;apiVersion&quot;:&quot;meta.k8s.io/v1beta1&quot;,&quot;metadata&quot;:{&quot;name&quot;:&quot;team01-student-ui-7f47864588-hz7gn&quot;,&quot;generateName&quot;:&quot;team01-student-ui-7f47864588-&quot;,&quot;namespace&quot;:&quot;team01&quot;,&quot;selfLink&quot;:&quot;/api/v1/namespaces/team01/pods/team01-student-ui-7f47864588-hz7gn&quot;,&quot;uid&quot;:&quot;7cd9d5ac-d81c-11e9-ab08-06c0ef66d8ff&quot;,&quot;resourceVersion&quot;:&quot;516858&quot;,&quot;creationTimestamp&quot;:&quot;2019-09-16T00:54:07Z&quot;,&quot;labels&quot;:{&quot;app&quot;:&quot;team01-student-ui&quot;,&quot;pod-template-hash&quot;:&quot;3903420144&quot;},&quot;annotations&quot;:{&quot;openshift.io/scc&quot;:&quot;restricted&quot;},&quot;ownerReferences&quot;:[{&quot;apiVersion&quot;:&quot;apps/v1&quot;,&quot;kind&quot;:&quot;ReplicaSet&quot;,&quot;name&quot;:&quot;team01-student-ui-7f47864588&quot;,&quot;uid&quot;:&quot;7cd76843-d81c-11e9-ab08-06c0ef66d8ff&quot;,&quot;controller&quot;:true,&quot;blockOwnerDeletion&quot;:true}]}}}]}<br>    I0917 19:28:48.105754   66924 get.go:443] no kind is registered for the type v1beta1.Table in scheme &quot;k8s.io/kubernetes/pkg/api/legacyscheme/scheme.go:29&quot;<br>    NAME                                 READY     STATUS    RESTARTS   AGE<br>    team01-student-ui-7f47864588-hz7gn   1/1       Running   0          1d<br></code></pre><br><blockquote><br><div><button class="btn btn-success" onclick="markComplete('CS-102 :- MarkComplete 1022 ConfirmButton T18')">Press to mark completed</button></div></blockquote><hr><p>The &quot;oc get&quot; command provides an ability to view realtime actions of the resource that is the focus of the get. Provide an additional parameter, <strong>--watch</strong>.</p><p>View realtime events for all namespaces in the cluster.  Be sure to include the <strong>--watch</strong> parameter.</p><p>To stop realtime viewing escape or Control-C the terminal output to exit the command.</p><p>Ensure to include the --all-namespaces and --watch parameters.</p><br><pre><code><br>Command:<br><br>    oc get events --all-namespaces --watch <br><br>Example output:<br><br>    NAMESPACE              LAST SEEN   FIRST SEEN   COUNT     NAME                                        KIND                   SUBOBJECT                             TYPE      REASON           SOURCE                                 MESSAGE<br>    default                3m          4d           1185      ansible-service-broker.15c41d2da5b24ada     ClusterServiceBroker                                         Normal    FetchedCatalog   service-catalog-controller-manager     Successfully fetched catalog entries from broker.<br>    default                7m          4d           594       template-service-broker.15c41d2ce1a60932    ClusterServiceBroker                                         Normal    FetchedCatalog   service-catalog-controller-manager     Successfully fetched catalog entries from broker.<br>    kube-service-catalog   1h          7h           3         apiserver-gs79m.15c5485c2851f574            Pod                    spec.containers{apiserver}            Warning   Unhealthy        kubelet, sydney.52.117.155.26.nip.io   Readiness probe failed: HTTP probe failed with statuscode: 500<br>    kube-service-catalog   1h          7h           3         controller-manager-6dtd6.15c5485d06865607   Pod                    spec.containers{controller-manager}   Warning   Unhealthy        kubelet, sydney.52.117.155.26.nip.io   Readiness probe failed: HTTP probe failed with statuscode: 500        <br></code></pre><br><blockquote><br><div><button class="btn btn-success" onclick="markComplete('CS-102 :- MarkComplete 1023 ConfirmButton T18')">Press to mark completed</button></div></blockquote>